# å•å¸§3Då§¿æ€ç”Ÿæˆä½¿ç”¨è¯´æ˜

## ğŸ“– æ¦‚è¿°

`sample_single_pose.py` æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äº**ä»æ–‡æœ¬ç”Ÿæˆé™æ€å•å¸§3Då§¿æ€**çš„è„šæœ¬ã€‚

ä¸ `sample.py` ç”Ÿæˆå®Œæ•´è¿åŠ¨åºåˆ—ä¸åŒï¼Œè¿™ä¸ªè„šæœ¬ä¼šï¼š
1. ç”Ÿæˆä¸€ä¸ªçŸ­çš„è¿åŠ¨åºåˆ—ï¼ˆé»˜è®¤16å¸§ï¼‰
2. ä»ä¸­æå–æŒ‡å®šçš„ä¸€å¸§ä½œä¸ºé™æ€å§¿æ€
3. ä¿å­˜ä¸ºNPYã€JSONå’Œå›¾ç‰‡æ ¼å¼

**é€‚ç”¨åœºæ™¯**ï¼š
- ç”Ÿæˆ"ä¸¾æ‰‹"ã€"åç€"ã€"ç«™ç«‹"ç­‰é™æ€å§¿æ€
- å¿«é€Ÿé¢„è§ˆæŸä¸ªåŠ¨ä½œçš„å…³é”®å¸§
- ä¸ºå…¶ä»–åº”ç”¨æä¾›åˆå§‹å§¿æ€
- åˆ†æç‰¹å®šå§¿æ€çš„å…³èŠ‚ç‚¹ä½ç½®

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ç”¨æ³•

```bash
# ç”Ÿæˆ"ä¸¾æ‰‹"å§¿æ€
python sample_single_pose.py \
    --text_prompt "A person raising both hands" \
    --dataset_name t2m \
    --save_image \
    --save_json
```

### æŒ‡å®šå¸§ç´¢å¼•

```bash
# æå–ç¬¬ä¸€å¸§ï¼ˆåŠ¨ä½œå¼€å§‹ï¼‰
python sample_single_pose.py \
    --text_prompt "A person waving hand" \
    --frame_index 0 \
    --save_image

# æå–æœ€åä¸€å¸§ï¼ˆåŠ¨ä½œç»“æŸï¼‰
python sample_single_pose.py \
    --text_prompt "A person waving hand" \
    --frame_index -2 \
    --save_image

# æå–ä¸­é—´å¸§ï¼ˆåŠ¨ä½œé«˜æ½®ï¼Œé»˜è®¤ï¼‰
python sample_single_pose.py \
    --text_prompt "A person jumping" \
    --frame_index -1 \
    --save_image
```

### æ‰¹é‡ç”Ÿæˆå¤šä¸ªå§¿æ€

```bash
# åˆ›å»ºæ–‡æœ¬æ–‡ä»¶
cat > poses.txt << EOF
A person raising left hand
A person sitting on a chair
A person standing with arms crossed
A person kneeling down
EOF

# æ‰¹é‡ç”Ÿæˆ
python sample_single_pose.py \
    --text_path poses.txt \
    --dataset_name t2m \
    --repeat_times 5 \
    --save_image \
    --save_json
```

---

## ğŸ“‹ å‚æ•°è¯´æ˜

### å¿…éœ€å‚æ•°

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--text_prompt` | å•ä¸ªæ–‡æœ¬æè¿° | `"A person raising both hands"` |
| `--text_path` | æ–‡æœ¬æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ | `poses.txt` |

**æ³¨æ„**: `--text_prompt` å’Œ `--text_path` å¿…é¡»æä¾›å…¶ä¸­ä¸€ä¸ª

### æ¨¡å‹å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--dataset_name` | `t2m` | æ•°æ®é›†åç§°ï¼š`t2m`, `kit`, `eval_t2m`, `eval_kit` |
| `--checkpoints_dir` | `./checkpoints` | æ¨¡å‹checkpointç›®å½• |
| `--name` | `MARDM` | MARDMæ¨¡å‹åç§° |
| `--ae_name` | `AE` | AutoEncoderåç§° |

### ç”Ÿæˆå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--sequence_length` | `16` | ç”Ÿæˆåºåˆ—é•¿åº¦ï¼ˆå¸§æ•°ï¼‰ï¼Œ**å¿…é¡»æ˜¯4çš„å€æ•°** |
| `--frame_index` | `-1` | æå–å¸§ç´¢å¼•ï¼Œ`-1`=ä¸­é—´å¸§ï¼Œ`0`=ç¬¬ä¸€å¸§ï¼Œ`-2`=æœ€åä¸€å¸§ |
| `--repeat_times` | `3` | æ¯ä¸ªæç¤ºè¯ç”Ÿæˆå¤šå°‘ä¸ªä¸åŒå§¿æ€ |
| `--seed` | `3407` | éšæœºç§å­ |
| `--time_steps` | `18` | æ‰©æ•£æ­¥æ•° |
| `--cfg` | `4.5` | Classifier-free guidanceå¼ºåº¦ |

### è¾“å‡ºå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--save_json` | `False` | æ˜¯å¦ä¿å­˜JSONæ ¼å¼ï¼ˆæ·»åŠ æ­¤å‚æ•°å³å¼€å¯ï¼‰ |
| `--save_image` | `False` | æ˜¯å¦ä¿å­˜PNGå›¾ç‰‡ï¼ˆæ·»åŠ æ­¤å‚æ•°å³å¼€å¯ï¼‰ |

---

## ğŸ¯ æå–ä¸åŒçš„å…³é”®å¸§

ä¸åŒçš„å¸§ç´¢å¼•é€‚åˆä¸åŒç±»å‹çš„åŠ¨ä½œï¼š

### 1. ä¸­é—´å¸§ï¼ˆé»˜è®¤ï¼Œ`--frame_index -1`ï¼‰

**é€‚ç”¨äº**: åŠ¨ä½œçš„**é«˜æ½®/æœ€æ˜¾è‘—**æ—¶åˆ»

```bash
# ä¸¾æ‰‹ â†’ æ‰‹è‡‚ä¸¾åˆ°æœ€é«˜
python sample_single_pose.py --text_prompt "A person raising hands" --save_image

# è·³è·ƒ â†’ è·³åˆ°æœ€é«˜ç‚¹
python sample_single_pose.py --text_prompt "A person jumping" --save_image

# è¸¢è…¿ â†’ è…¿è¸¢åˆ°æœ€é«˜
python sample_single_pose.py --text_prompt "A person kicking" --save_image
```

### 2. ç¬¬ä¸€å¸§ï¼ˆ`--frame_index 0`ï¼‰

**é€‚ç”¨äº**: åŠ¨ä½œçš„**èµ·å§‹å§¿æ€**

```bash
# æŒ¥æ‰‹ â†’ æ‰‹è‡‚åˆšå¼€å§‹æŠ¬èµ·
python sample_single_pose.py --text_prompt "A person waving" --frame_index 0 --save_image

# åä¸‹ â†’ ç«™ç«‹å§¿æ€ï¼ˆå‡†å¤‡åï¼‰
python sample_single_pose.py --text_prompt "A person sitting down" --frame_index 0 --save_image
```

### 3. æœ€åä¸€å¸§ï¼ˆ`--frame_index -2`ï¼‰

**é€‚ç”¨äº**: åŠ¨ä½œçš„**ç»“æŸå§¿æ€**

```bash
# åä¸‹ â†’ ååœ¨æ¤…å­ä¸Š
python sample_single_pose.py --text_prompt "A person sitting down" --frame_index -2 --save_image

# è¹²ä¸‹ â†’ å®Œå…¨è¹²ä¸‹çš„å§¿æ€
python sample_single_pose.py --text_prompt "A person squatting" --frame_index -2 --save_image
```

### 4. è‡ªå®šä¹‰å¸§ï¼ˆ`--frame_index <æ•°å­—>`ï¼‰

**é€‚ç”¨äº**: éœ€è¦**ç²¾ç¡®æ§åˆ¶**çš„åœºæ™¯

```bash
# æå–ç¬¬8å¸§ï¼ˆé€‚åˆ16å¸§åºåˆ—çš„ä¸­é—´ï¼‰
python sample_single_pose.py --text_prompt "A person dancing" --frame_index 8 --save_image

# æå–ç¬¬3å¸§ï¼ˆåŠ¨ä½œæ—©æœŸï¼‰
python sample_single_pose.py --text_prompt "A person walking" --frame_index 3 --save_image
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶

### æ–‡ä»¶ç»“æ„

```
generation/
â””â”€â”€ MARDM_t2m_single_pose/
    â””â”€â”€ 0/  # ç¬¬0ä¸ªæç¤ºè¯
        â”œâ”€â”€ caption:A person raising both hands_sample0_repeat0_frame8.npy   # NPYæ ¼å¼
        â”œâ”€â”€ caption:A person raising both hands_sample0_repeat0_frame8.json  # JSONæ ¼å¼
        â”œâ”€â”€ caption:A person raising both hands_sample0_repeat0_frame8.png   # å¯è§†åŒ–å›¾ç‰‡
        â”œâ”€â”€ caption:A person raising both hands_sample0_repeat1_frame8.npy   # é‡å¤1
        â””â”€â”€ ...
```

### NPYæ–‡ä»¶æ ¼å¼

```python
import numpy as np

# åŠ è½½å•å¸§å§¿æ€
pose = np.load('caption:A person raising both hands_sample0_repeat0_frame8.npy')

print(pose.shape)  # (22, 3) - 22ä¸ªå…³èŠ‚ç‚¹ï¼Œæ¯ä¸ª3ä¸ªåæ ‡(X, Y, Z)

# ç¤ºä¾‹æ•°æ®
# pose[0]  -> [0.0000, 0.9394, 0.0000]  # éª¨ç›†
# pose[15] -> [0.0028, 1.6250, 0.0122]  # å¤´éƒ¨
# pose[20] -> [0.5234, 1.8456, 0.1234]  # å·¦æ‰‹è…•
# pose[21] -> [-0.5123, 1.8234, 0.1123] # å³æ‰‹è…•
```

### JSONæ–‡ä»¶æ ¼å¼

```json
{
  "caption": "A person raising both hands",
  "frame_index": 8,
  "num_joints": 22,
  "joints": [
    [0.0000, 0.9394, 0.0000],  // å…³èŠ‚ç‚¹0: éª¨ç›†
    [0.0632, 0.8582, 0.0012],  // å…³èŠ‚ç‚¹1: å³é«‹
    // ... æ›´å¤šå…³èŠ‚ç‚¹
  ],
  "joint_names": [
    "pelvis", "left_hip", "right_hip", "spine1",
    "left_knee", "right_knee", "spine2", "left_ankle",
    "right_ankle", "spine3", "left_foot", "right_foot",
    "neck", "left_collar", "right_collar", "head",
    "left_shoulder", "right_shoulder", "left_elbow",
    "right_elbow", "left_wrist", "right_wrist"
  ]
}
```

### PNGå›¾ç‰‡

3Då¯è§†åŒ–å›¾ç‰‡ï¼Œæ˜¾ç¤ºï¼š
- éª¨æ¶ç»“æ„ï¼ˆä¸åŒé¢œè‰²çš„éª¨éª¼è¿æ¥ï¼‰
- å…³èŠ‚ç‚¹ä½ç½®ï¼ˆçº¢è‰²ç‚¹ï¼‰
- æ ‡é¢˜ï¼ˆåŒ…å«æ–‡æœ¬æè¿°å’Œå¸§ç´¢å¼•ï¼‰

---

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

### 1. ç”Ÿæˆå¤šæ ·æ€§

é€šè¿‡ `--repeat_times` ç”ŸæˆåŒä¸€æè¿°çš„å¤šä¸ªä¸åŒå§¿æ€ï¼š

```bash
# ç”Ÿæˆ10ä¸ªä¸åŒçš„"ä¸¾æ‰‹"å§¿æ€
python sample_single_pose.py \
    --text_prompt "A person raising both hands" \
    --repeat_times 10 \
    --save_image
```

ç„¶åå¯ä»¥æ‰‹åŠ¨æŒ‘é€‰æœ€å¥½çš„ä¸€ä¸ªã€‚

### 2. è°ƒæ•´ç”Ÿæˆè´¨é‡

```bash
# æé«˜ç”Ÿæˆè´¨é‡ï¼ˆæ›´æ…¢ä½†æ›´å¥½ï¼‰
python sample_single_pose.py \
    --text_prompt "A person in yoga pose" \
    --time_steps 50 \
    --cfg 5.0 \
    --save_image

# å¿«é€Ÿç”Ÿæˆï¼ˆæ›´å¿«ä½†è´¨é‡å¯èƒ½ç¨å·®ï¼‰
python sample_single_pose.py \
    --text_prompt "A person standing" \
    --time_steps 10 \
    --cfg 3.0 \
    --sequence_length 8
```

### 3. ä¸åŒéšæœºç§å­

æ”¹å˜ `--seed` å¾—åˆ°ä¸åŒçš„ç»“æœï¼š

```bash
for seed in 0 1 2 3 4; do
    python sample_single_pose.py \
        --text_prompt "A person dancing" \
        --seed $seed \
        --save_image
done
```

### 4. åºåˆ—é•¿åº¦çš„é€‰æ‹©

| åºåˆ—é•¿åº¦ | é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|---------|------|----------|
| 4-8å¸§ | âš¡âš¡âš¡ å¾ˆå¿« | å¿«é€Ÿé¢„è§ˆã€æ‰¹é‡ç”Ÿæˆ |
| 12-16å¸§ | âš¡âš¡ è¾ƒå¿« | **æ¨è** - å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡ |
| 20-32å¸§ | âš¡ è¾ƒæ…¢ | éœ€è¦æ›´å¤šä¸­é—´å¸§é€‰æ‹© |
| 40+å¸§ | ğŸŒ æ…¢ | å®Œæ•´åŠ¨ä½œï¼Œä¸æ¨èç”¨äºå•å¸§ |

```bash
# å¿«é€Ÿç”Ÿæˆï¼ˆ8å¸§ï¼Œæå–ç¬¬4å¸§ï¼‰
python sample_single_pose.py \
    --text_prompt "A person raising hand" \
    --sequence_length 8 \
    --frame_index 4 \
    --save_image
```

---

## ğŸ¨ ç¤ºä¾‹åœºæ™¯

### åœºæ™¯1: äººç‰©åˆå§‹å§¿æ€åº“

ä¸ºæ¸¸æˆæˆ–åŠ¨ç”»åˆ›å»ºå¤šç§åˆå§‹å§¿æ€ï¼š

```bash
cat > initial_poses.txt << EOF
A person standing naturally
A person standing with arms at sides
A person standing with hands on hips
A person standing with arms crossed
A person in a relaxed standing pose
EOF

python sample_single_pose.py \
    --text_path initial_poses.txt \
    --frame_index 0 \
    --repeat_times 5 \
    --save_image \
    --save_json
```

### åœºæ™¯2: ç‘œä¼½/å¥èº«åŠ¨ä½œå§¿æ€

```bash
cat > yoga_poses.txt << EOF
A person in tree pose
A person in warrior pose
A person in downward dog pose
A person in cobra pose
A person in child pose
EOF

python sample_single_pose.py \
    --text_path yoga_poses.txt \
    --frame_index -1 \
    --repeat_times 3 \
    --save_image \
    --save_json
```

### åœºæ™¯3: ç‰¹å®šåŠ¨ä½œçš„å…³é”®å¸§

```bash
# æŒ¥æ‰‹çš„3ä¸ªå…³é”®å¸§
python sample_single_pose.py --text_prompt "A person waving hand" --frame_index 0 --save_image  # å¼€å§‹
python sample_single_pose.py --text_prompt "A person waving hand" --frame_index -1 --save_image # é«˜å³°
python sample_single_pose.py --text_prompt "A person waving hand" --frame_index -2 --save_image # ç»“æŸ
```

### åœºæ™¯4: æƒ…æ„Ÿå§¿æ€

```bash
cat > emotion_poses.txt << EOF
A person celebrating with arms raised
A person looking sad with head down
A person shrugging shoulders
A person pointing forward
A person clapping hands
EOF

python sample_single_pose.py \
    --text_path emotion_poses.txt \
    --repeat_times 5 \
    --save_image \
    --save_json
```

---

## ğŸ”§ åå¤„ç†è„šæœ¬ç¤ºä¾‹

### 1. æ‰¹é‡è¯»å–å¹¶åˆ†æå§¿æ€

```python
import numpy as np
import os
from glob import glob

# è¯»å–æ‰€æœ‰NPYæ–‡ä»¶
npy_files = glob('generation/MARDM_t2m_single_pose/*/*.npy')

for npy_file in npy_files:
    pose = np.load(npy_file)
    
    # åˆ†æå§¿æ€ç‰¹å¾
    pelvis_height = pose[0, 1]  # éª¨ç›†é«˜åº¦
    head_height = pose[15, 1]   # å¤´éƒ¨é«˜åº¦
    
    left_hand_height = pose[20, 1]   # å·¦æ‰‹é«˜åº¦
    right_hand_height = pose[21, 1]  # å³æ‰‹é«˜åº¦
    
    print(f"\næ–‡ä»¶: {os.path.basename(npy_file)}")
    print(f"  èº«ä½“é«˜åº¦: {head_height - pelvis_height:.3f} ç±³")
    print(f"  å·¦æ‰‹é«˜åº¦: {left_hand_height:.3f} ç±³")
    print(f"  å³æ‰‹é«˜åº¦: {right_hand_height:.3f} ç±³")
    
    # åˆ¤æ–­å§¿æ€ç±»å‹
    if left_hand_height > head_height or right_hand_height > head_height:
        print(f"  â†’ æ£€æµ‹åˆ°: ä¸¾æ‰‹å§¿æ€ âœ‹")
    elif pelvis_height < 0.6:
        print(f"  â†’ æ£€æµ‹åˆ°: è¹²/åå§¿æ€ ğŸª‘")
    else:
        print(f"  â†’ æ£€æµ‹åˆ°: ç«™ç«‹å§¿æ€ ğŸ§")
```

### 2. ç­›é€‰ç¬¦åˆæ¡ä»¶çš„å§¿æ€

```python
import numpy as np
import shutil
import os
from glob import glob

def is_hands_raised(pose):
    """åˆ¤æ–­æ˜¯å¦æ˜¯ä¸¾æ‰‹å§¿æ€"""
    head_height = pose[15, 1]
    left_hand_height = pose[20, 1]
    right_hand_height = pose[21, 1]
    
    # è‡³å°‘ä¸€åªæ‰‹é«˜äºå¤´éƒ¨
    return left_hand_height > head_height or right_hand_height > head_height

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs('selected_poses', exist_ok=True)

# ç­›é€‰ä¸¾æ‰‹å§¿æ€
npy_files = glob('generation/MARDM_t2m_single_pose/*/*.npy')
selected_count = 0

for npy_file in npy_files:
    pose = np.load(npy_file)
    
    if is_hands_raised(pose):
        # å¤åˆ¶åˆ°selectedç›®å½•
        dest = os.path.join('selected_poses', os.path.basename(npy_file))
        shutil.copy(npy_file, dest)
        selected_count += 1
        print(f"âœ… é€‰ä¸­: {os.path.basename(npy_file)}")

print(f"\nå…±ç­›é€‰å‡º {selected_count} ä¸ªä¸¾æ‰‹å§¿æ€")
```

### 3. è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼

```python
import numpy as np
import json

def npy_to_dict(npy_file):
    """å°†NPYè½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
    pose = np.load(npy_file)
    
    joint_names = [
        "pelvis", "left_hip", "right_hip", "spine1", "left_knee", "right_knee",
        "spine2", "left_ankle", "right_ankle", "spine3", "left_foot",
        "right_foot", "neck", "left_collar", "right_collar", "head",
        "left_shoulder", "right_shoulder", "left_elbow", "right_elbow",
        "left_wrist", "right_wrist"
    ]
    
    return {
        name: {
            "x": float(pose[i, 0]),
            "y": float(pose[i, 1]),
            "z": float(pose[i, 2])
        }
        for i, name in enumerate(joint_names)
    }

# ä½¿ç”¨ç¤ºä¾‹
pose_dict = npy_to_dict('generation/MARDM_t2m_single_pose/0/caption:A person raising hands_sample0_repeat0_frame8.npy')

# ä¿å­˜ä¸ºJSON
with open('pose_readable.json', 'w') as f:
    json.dump(pose_dict, f, indent=2)

print("è½¬æ¢å®Œæˆï¼")
print(f"å·¦æ‰‹è…•ä½ç½®: {pose_dict['left_wrist']}")
print(f"å³æ‰‹è…•ä½ç½®: {pose_dict['right_wrist']}")
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆè¦å…ˆç”Ÿæˆåºåˆ—å†æå–å•å¸§ï¼Ÿ

**A**: MARDMæ˜¯è®­ç»ƒç”¨äºç”Ÿæˆè¿åŠ¨åºåˆ—çš„ï¼Œç›´æ¥ç”Ÿæˆå•å¸§å¯èƒ½æ•ˆæœä¸å¥½ã€‚é€šè¿‡ç”ŸæˆçŸ­åºåˆ—å†æå–ï¼Œå¯ä»¥ï¼š
1. åˆ©ç”¨æ—¶åºä¿¡æ¯ç”Ÿæˆæ›´è‡ªç„¶çš„å§¿æ€
2. é€‰æ‹©åŠ¨ä½œçš„ä¸åŒé˜¶æ®µï¼ˆå¼€å§‹/é«˜æ½®/ç»“æŸï¼‰
3. ç”Ÿæˆè´¨é‡æ›´å¥½

### Q2: å¦‚ä½•ç”Ÿæˆ"é™æ­¢ç«™ç«‹"çš„å§¿æ€ï¼Ÿ

**A**: ä½¿ç”¨æè¿°é™æ€å§¿æ€çš„æ–‡æœ¬ï¼š

```bash
python sample_single_pose.py \
    --text_prompt "A person standing still" \
    --sequence_length 8 \
    --frame_index 4
```

æˆ–è€…ç”Ÿæˆä»»ä½•åŠ¨ä½œçš„ç¬¬ä¸€å¸§ï¼š

```bash
python sample_single_pose.py \
    --text_prompt "A person walking" \
    --frame_index 0
```

### Q3: ç”Ÿæˆçš„å§¿æ€ä¸å¤Ÿå¤šæ ·æ€ä¹ˆåŠï¼Ÿ

**A**: 
1. å¢åŠ  `--repeat_times`
2. æ”¹å˜ `--seed`
3. è°ƒæ•´ `--temperature`ï¼ˆæ›´é«˜=æ›´å¤šæ ·ï¼‰
4. æ”¹å˜ `--frame_index`ï¼ˆä¸åŒå¸§ï¼‰

```bash
python sample_single_pose.py \
    --text_prompt "A person raising hand" \
    --repeat_times 10 \
    --temperature 1.2
```

### Q4: å…³èŠ‚ç‚¹åæ ‡çš„å•ä½æ˜¯ä»€ä¹ˆï¼Ÿ

**A**: **ç±³ï¼ˆmeterï¼‰**ã€‚å‚è€ƒï¼š
- æˆå¹´äººèº«é«˜çº¦ 1.7 ç±³
- éª¨ç›†é«˜åº¦çº¦ 0.9 ç±³ï¼ˆç«™ç«‹æ—¶ï¼‰
- æ‰‹è‡‚é•¿åº¦çº¦ 0.6 ç±³

è¯¦è§ `åæ ‡è¡¨ç¤ºæ–¹å¼è¯´æ˜.md`

### Q5: å¦‚ä½•éªŒè¯ç”Ÿæˆçš„å§¿æ€æ˜¯å¦æ­£ç¡®ï¼Ÿ

**A**: 
1. ä½¿ç”¨ `--save_image` å¯è§†åŒ–æŸ¥çœ‹
2. æ£€æŸ¥å…³èŠ‚ç‚¹é«˜åº¦ï¼ˆYåæ ‡ï¼‰æ˜¯å¦åˆç†
3. æ£€æŸ¥èº«ä½“æ¯”ä¾‹æ˜¯å¦è‡ªç„¶

```python
import numpy as np

pose = np.load('pose.npy')

# æ£€æŸ¥é«˜åº¦åˆç†æ€§
pelvis_y = pose[0, 1]
head_y = pose[15, 1]
body_height = head_y - pelvis_y

print(f"èº«ä½“é«˜åº¦: {body_height:.2f} ç±³")
# åº”è¯¥åœ¨ 0.6-0.9 ç±³ä¹‹é—´ï¼ˆç«™ç«‹æ—¶ï¼‰

# æ£€æŸ¥è„šæ˜¯å¦åœ¨åœ°é¢
left_foot_y = pose[10, 1]
right_foot_y = pose[11, 1]
print(f"å·¦è„šé«˜åº¦: {left_foot_y:.3f} ç±³")
print(f"å³è„šé«˜åº¦: {right_foot_y:.3f} ç±³")
# åº”è¯¥æ¥è¿‘ 0 ç±³
```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- `å…³èŠ‚ç‚¹é¡ºåºè¯´æ˜.md` - 22ä¸ªå…³èŠ‚ç‚¹çš„è¯¦ç»†è¯´æ˜
- `åæ ‡è¡¨ç¤ºæ–¹å¼è¯´æ˜.md` - XYZåæ ‡ç³»ç»Ÿè¯´æ˜
- `å¯è§†åŒ–ä»£ç è¯´æ˜.md` - 3Då¯è§†åŒ–åŸç†
- `sample_flexibleä½¿ç”¨è¯´æ˜.md` - å®Œæ•´åºåˆ—ç”Ÿæˆ

---

## ğŸ“Š æ€§èƒ½å‚è€ƒ

åœ¨ NVIDIA RTX 3090 GPU ä¸Šçš„æµ‹è¯•ç»“æœï¼š

| åºåˆ—é•¿åº¦ | å•ä¸ªå§¿æ€ç”Ÿæˆæ—¶é—´ | æ¨èåœºæ™¯ |
|---------|----------------|----------|
| 4å¸§ | ~2ç§’ | å¿«é€Ÿé¢„è§ˆ |
| 8å¸§ | ~3ç§’ | æ‰¹é‡ç”Ÿæˆ |
| 16å¸§ | ~5ç§’ | **æ¨è** |
| 32å¸§ | ~8ç§’ | éœ€è¦æ›´å¤šé€‰æ‹© |

**æç¤º**: ä½¿ç”¨ `--sequence_length 8` å¯ä»¥åœ¨2-3ç§’å†…ç”Ÿæˆå•å¸§å§¿æ€ï¼

---

## ğŸ¯ æ€»ç»“

**æ ¸å¿ƒå‘½ä»¤**:

```bash
# æœ€ç®€å•çš„ç”¨æ³•
python sample_single_pose.py --text_prompt "A person raising hands" --save_image

# æ¨èç”¨æ³•ï¼ˆå¤šæ ·æ€§ + å¯è§†åŒ– + JSONï¼‰
python sample_single_pose.py \
    --text_prompt "A person raising hands" \
    --repeat_times 5 \
    --save_image \
    --save_json

# æ‰¹é‡ç”Ÿæˆ
python sample_single_pose.py \
    --text_path my_poses.txt \
    --repeat_times 3 \
    --save_image \
    --save_json
```

äº«å—å•å¸§å§¿æ€ç”Ÿæˆå§ï¼ğŸ‰

